{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loading\n",
    "\n",
    "dataset = 'ECG'\n",
    "\n",
    "# 使用函数创建数据集\n",
    "data_dir = 'raw\\ECG'\n",
    "train_dataset, test_dataset = load_ecg_data(data_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network has 3647 weights that need to be deployed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the number of classes for the classification task\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize the model with the given configuration and number of classes, and move it to the specified device\n",
    "model = NET_32k_ECG(num_classes).to(device)\n",
    "\n",
    "total_weights = count_weights(model)\n",
    "print(f\"The network has {total_weights} weights that need to be deployed.\")\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "model = torch.quantization.prepare_qat(model, inplace=True)\n",
    "model = torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET_32k_ECG(\n",
      "  (quant): Quantize(scale=tensor([0.0376]), zero_point=tensor([46]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      "  (conv1_depthwise): QuantizedConv1d(1, 1, kernel_size=(7,), stride=(1,), scale=0.034143365919589996, zero_point=70, padding=(4,), dilation=(2,))\n",
      "  (conv1_pointwise): QuantizedConv1d(1, 40, kernel_size=(1,), stride=(1,), scale=0.03150835260748863, zero_point=70)\n",
      "  (bn1): QuantizedBatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): QuantizedHardswish()\n",
      "  (conv2_depthwise): QuantizedConv1d(40, 40, kernel_size=(5,), stride=(1,), scale=0.07373173534870148, zero_point=66, padding=(1,), groups=40)\n",
      "  (conv2_pointwise): QuantizedConv1d(40, 40, kernel_size=(1,), stride=(1,), scale=0.2259116917848587, zero_point=61)\n",
      "  (activation2): QuantizedHardswish()\n",
      "  (conv3_depthwise): QuantizedConv1d(40, 40, kernel_size=(3,), stride=(1,), scale=0.0875716507434845, zero_point=49, padding=(1,), groups=40)\n",
      "  (conv3_pointwise): QuantizedConv1d(40, 40, kernel_size=(1,), stride=(1,), scale=0.14141187071800232, zero_point=43)\n",
      "  (activation3): QuantizedHardswish()\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): QuantizedLinear(in_features=40, out_features=2, scale=0.21307983994483948, zero_point=11, qscheme=torch.per_channel_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "# Specify the filename of the saved model\n",
    "model_filename = f\"checkpoint/ECG-3647-99.40_model.t7\"\n",
    "\n",
    "# Load the checkpoint from the file, mapping the model to the specified device\n",
    "checkpoint = torch.load(model_filename, map_location=device)\n",
    "\n",
    "# Load the model state dictionary from the checkpoint\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print(model) # The model has been quantized to int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting weights from layer: conv1_depthwise\n",
      "Weight Shape: (7,), Int8 Weights:\n",
      "[   0    7   -4   46   27 -128   42]\n",
      "\n",
      "Extracting weights from layer: conv1_pointwise\n",
      "Weight Shape: (40,), Int8 Weights:\n",
      "[ 127 -127  127  127  127 -128 -127  127 -128  127  127 -127  127 -128\n",
      " -127  127 -128  127  127  127  127 -127 -128  127 -128 -128  127  127\n",
      "  127 -128  127  127 -127 -128 -127  127  127  127 -128 -128]\n",
      "\n",
      "Extracting weights from layer: conv2_depthwise\n",
      "Weight Shape: (200,), Int8 Weights:\n",
      "[  64  -95   96   56 -128 -120   17  127   90   16 -128   99   85   34\n",
      "  -14 -110  112   87 -128 -126 -128  -38   41   42    5   84  -69 -127\n",
      "   80   54   16   -3   39  126 -128 -128  112  -82   46   -5   85   34\n",
      "   15  -55 -127 -128   56   80   46   95  107  127   12  -51  -90  -62\n",
      " -106   91   -6 -128  127  -91  -31  -17   -8   69   31  127  -73  109\n",
      "  -73    2   28   62  127  -46  -65 -127   63   -1  -44  127  -67  -91\n",
      " -104   77 -128   -2 -101   65    9  106   74 -128  -92 -127   45   -1\n",
      "  127  127    1 -128   18   58   35 -103  -20  127   41  -78  -94  -29\n",
      "  -75  127   38 -107 -128  -74   -8  106  -61  -75  -19    3  127 -128\n",
      "   36  121   23  -83   -3  -85   82  127   72  127 -112  -46   47  -39\n",
      "  -96   95 -128   18   30  -96   13  127  -29  -37  -49  -22  -26  127\n",
      "   90  -31 -128  -65   62  -50   41  127   17  -18  -64    9  100 -128\n",
      "  -39   90 -127  -82  -99  127 -105  -70  127   -6  -67   -1   67   89\n",
      "   71 -127  -98  -31  127   36  -95    3   46   -6 -127   51   -3  -28\n",
      "   35   53   37  127]\n",
      "\n",
      "Extracting weights from layer: conv2_pointwise\n",
      "Weight Shape: (1600,), Int8 Weights:\n",
      "[ -2  18  52 ... -63  -5 -84]\n",
      "\n",
      "Extracting weights from layer: conv3_depthwise\n",
      "Weight Shape: (120,), Int8 Weights:\n",
      "[ 127   85   27 -128   97  -91  -88 -127  104  106   81  127 -128  -41\n",
      "   94  -82   43  127 -128   66   15  -30 -127  -28 -128  -21   -6  -53\n",
      " -128    6  112  127  -41 -121 -111 -128  127  126  -87   41  127   68\n",
      "  127  114   12  -96  -25 -128  127  -35   35 -128 -104  -55  -85  -53\n",
      " -128  127   44  -30  -79 -128  -64 -128  120   98  -43  -70  127  127\n",
      "  -63  -84  127  -29  -85  127   83 -109  -98 -128  -83  127  -39  109\n",
      "   70 -127   -4  127  116   78  127  -32  -92  -40 -128  -28   -1  -31\n",
      "  127 -128   14  119 -128  -10   86 -128  -84   82  -96  127    6  -87\n",
      "  -56  127  127  -11  -63  127  -62  -97]\n",
      "\n",
      "Extracting weights from layer: conv3_pointwise\n",
      "Weight Shape: (1600,), Int8 Weights:\n",
      "[  -5   70   -1 ...  -86   70 -114]\n",
      "\n",
      "Extracting weights from layer: fc\n",
      "Weight Shape: (80,), Int8 Weights:\n",
      "[ 120   38   -9   -8   28  127    8  -88  -79  -23    2  -52 -127  -20\n",
      "   42   19   77  -82  -55  -25  118  -16   83   48  -98   21  -42   75\n",
      "   97   66  -29   93  -79  -13  -47  123   -8   35   14   57   39  -55\n",
      "   41   68   22    4  -68  -53  -15   10   44   52    2  -59    7  -23\n",
      "  127  -46  -19   -4   16   -8    7   65   34  -75  -86  -34   29   61\n",
      "   34   -7   -7   35  117  -34  -19   42   91  -87]\n",
      "\n",
      "The test accuracy after quantization is: 99.40%\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the test dataset and store the accuracy\n",
    "model.eval()\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "\n",
    "# Extract the int8 weights from all quantized layers in the model and save them to a list\n",
    "quantized_weights_list = print_quantized_weights(model)\n",
    "\n",
    "print(f\"The test accuracy after quantization is: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto4ET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
