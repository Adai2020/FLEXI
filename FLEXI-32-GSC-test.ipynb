{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'yes' has 2377 audio files.\n",
      "Class 'no' has 2375 audio files.\n",
      "Class 'stop' has 2380 audio files.\n",
      "Class 'on' has 2367 audio files.\n",
      "Class 'off' has 2357 audio files.\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loading\n",
    "dataset = 'Google Speech Command (GSC)'\n",
    "\n",
    "data_path = 'raw/speech_commands'\n",
    "labels = ['yes', 'no', 'stop','on','off']\n",
    "\n",
    "train_dataset, test_dataset = load_speech_command_datasets(data_path, labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network has 2600 weights that need to be deployed.\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "# Initialize the model with the given configuration and number of classes, and move it to the specified device\n",
    "model = NET_32k_GSC(num_classes).to(device)\n",
    "\n",
    "total_weights = count_weights(model)\n",
    "print(f\"The network has {total_weights} weights that need to be deployed.\")\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "model = torch.quantization.prepare_qat(model, inplace=True)\n",
    "model = torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET_32k_GSC(\n",
      "  (conv1): QuantizedConv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), scale=0.027086596935987473, zero_point=64, padding=(2, 2))\n",
      "  (bn1): QuantizedBatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): QuantizedHardswish()\n",
      "  (conv2): QuantizedConv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), scale=0.12287382781505585, zero_point=80, padding=(1, 1))\n",
      "  (bn2): QuantizedBatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): QuantizedHardswish()\n",
      "  (conv3): QuantizedConv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), scale=0.07499497383832932, zero_point=54, padding=(1, 1))\n",
      "  (bn3): QuantizedBatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation3): QuantizedHardswish()\n",
      "  (fc): QuantizedLinear(in_features=192, out_features=5, scale=0.36147260665893555, zero_point=68, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "# Specify the filename of the saved model\n",
    "model_filename = f\"checkpoint/GSC-3560-97.13_model.t7\"\n",
    "\n",
    "# Load the checkpoint from the file, mapping the model to the specified device\n",
    "checkpoint = torch.load(model_filename, map_location=device)\n",
    "\n",
    "# Load the model state dictionary from the checkpoint\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print(model) # The model has been quantized to int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting weights from layer: conv1\n",
      "Weight Shape: (200,), Int8 Weights:\n",
      "[ 127  107  -26  -60 -104   37  125  -17    6  -84  -33  -29   36  -20\n",
      "   41  -91  -20   92   27   -2  -91  -20   29   40   42   58  -60 -104\n",
      " -128  -24   10  -25 -117  -98  -24  105   72  -29   24   -5   87  -50\n",
      "  -70  -17   -2  107   90   -1  -26   96  -77   31   17  -37   36  -79\n",
      "  -51   35   26   23  -44    0  -30  -27  -16   -9   45   72   71   33\n",
      "   26  127   49   59   19    3  -29   11  -35  -44   86    5  -61  -39\n",
      "  -33   15   -6  -27  -22   49  -38  -69   10   56   83 -128  -34   30\n",
      "   12   19  -48  -22   26   28  127   25 -100   -2   39   14  -12  -20\n",
      "   74   57  -95  -68   75   93  -98  -79  126  127  -40  -65 -113  -56\n",
      "  -61    0  -66 -106    7   -2   47   43  -96  -41  -40   41   11  -19\n",
      "   29   81  -18  -25  -45   69  124   77   17 -128   31  -66  -40   45\n",
      "  -23  -48   20  -20   78   36  -16  -10  -39  -12   62   42  -33   51\n",
      "  -30   85  -43  -67 -128  -98  -13  -85   -8   -1   65   30   -9   93\n",
      "  127   54  -55  -41   46  -68 -100  -83   74   61   -3   89   -4   43\n",
      "    8   22  -43  -11]\n",
      "\n",
      "Extracting weights from layer: conv2\n",
      "Weight Shape: (576,), Int8 Weights:\n",
      "[  -8  -33    5   33  -35  -46  -13  -74   10   26  -23  -22  -49  -64\n",
      "  -70   37   -9 -120  -16    8   26   11    0  -24   31    6  -70  -35\n",
      "  -59  -20   86   -4   77   -2   43   34 -122   -9   40    6   41   16\n",
      "   64   44   20   21  -14   19  -22  -63   14   77  -45  -71  -45  -49\n",
      "  -78    1  -37   24  -21 -127  -85   18   -7  -21  -24   33   40   11\n",
      "   27   13   12  -80  -63  -11  -83  -44   30  -44   26   67  -20  -94\n",
      "  -11  -12  -33   12  -37    4  -11  -34   24  -58  -34    2   34   32\n",
      "  -19  -38  -12   -5   35    7  -73   43 -127  -95  -30  -62  -31   84\n",
      "   10   -9   10   23   62   51   -2  -77   12  -25   44   29   -4   40\n",
      "   44   25   38  -85  -57  -29  -22  -84  -29   16  -64    3   40  -34\n",
      "    7   57   49   22   21  -36  -50  -64  -51    5 -127    9   51   -3\n",
      "  -25  -25  -49    2  -17  -17  -41   -7  -14   53   45  -32  -14   12\n",
      "    1  -34  -42   21   53   45   36  -83 -117  -39  -15   15  -22   17\n",
      "   33  -13  -18   21   27  -30  -38  -68    5   29  -21  -26   57  -33\n",
      "  -45  -11  -45  -18  -35   33  -85 -125   28   52   30  -93  -23  -11\n",
      "   -1    9   24   59   14   14  -15   44    5   14   37   46  -28  -22\n",
      "  -10  -41  -56    5   19   14   21   26  -34  -14   -8  -90 -127   23\n",
      "   13   -7    4   17  -35   63  -19   32   22   -5  -11  -21  -12   11\n",
      "   29    3    2   18  -60  -55   27   34  -25   13  -40  -10  -19  -15\n",
      "   52   12   -9   37  -11   -6   31  -40  -38   24  -72  -89   16   48\n",
      "   39  -15   -9  -47  -73   12  -29  -12   12  -55  -56  -47  -91   -1\n",
      "  -14   -7   31  -64  -57  -88  -12   -3  -33   -7  -27  -17  -38   38\n",
      "   62   93   89   22   69  127   38    9   55   -2   23   -2  -53  -61\n",
      "  -70   23   26   34   80  -17  -11   26   -4  -43  -61   -5   10  -25\n",
      "   17  -25  -35  100   -8  -21  -40   19   71   -3   15   22  -25  -69\n",
      "   15  -27  -41   63  -49   17    5   46   35   94   28   95  100   21\n",
      "   83    3   14   82   16    6  -25   64   24   12  -56  -75  -13  -34\n",
      "    6  -92  -31  -29  -10   53  -27  -42   12  -70  -54  -21  -46   11\n",
      "   44  -41   41   52  -60  -86 -128  -23  -19  -56  -48 -123  -58    3\n",
      "    4   42  105  -39  -20  -92  -92  -66    0   30  -73  -90  -70  -72\n",
      "   46    9  -94   87   47  -14    5    3   -2  -41  -65   65   18   -2\n",
      "  -13 -127  -71   13   24  -41  -48   18   -4   -7    6  -20  -13    3\n",
      "   -3   -6   -9    7    2   27   28   24  -12   25   40  -14  -27  -14\n",
      "  -56  -23   16    2   13   16  -15   44  -21   30  -13  -66  -15  -13\n",
      "  -40  -34  -23  -27   18    2  -13    4    4    7   -8   13   30   -3\n",
      "    4   18    6   -8   16  -68   -4  -18  -16   14  -12    3   39   22\n",
      "   23   37   20    7   86  127  -59  -60   79   13    4   34   -6  -23\n",
      "   -6 -108  -83  -29   23  -21   22   -6  -12  -23   30    5  -11   21\n",
      "    2    6  -22  -28   -3  -32  -66  -55  -55  -62   -8  -77   42  -13\n",
      "  -66   44   -9  -26  -15   14  -37   28  -12 -124  -50   11   70   67\n",
      "   82   -1   32    6    1   15  -39   -8   -8  -45    1   -9   31   -4\n",
      "   40   -3]\n",
      "\n",
      "Extracting weights from layer: conv3\n",
      "Weight Shape: (864,), Int8 Weights:\n",
      "[   5   -9  -33   20  -49  -73   17   26  -55   18   81   62  -74  127\n",
      "   95    4  -95   40  -14  -34   20  -52   64   11  -14  121    1   69\n",
      "  -55  -59  -54   -6  -37   -7   14   75   45   -9  -18   27  -75  -30\n",
      "   40   36  -48   27   34   31   40  -33  -86   12   60 -100 -107   15\n",
      "   43  -56  -24  -99   85   16  -84  -26  -33   37  -38   68   28   50\n",
      "   11   41  -36  -36   26  -27  -18  -11   20  -62    6    0    2  -43\n",
      "   75   32  -17 -128  113   94  -55   16   76   24  -38  -65    9    8\n",
      "    7    6  -10   47  -51  -11  -35  -42   19  -20  -22   -9   64   -1\n",
      "  -22  -28   76  -36    1   31  -22  -69  -39   27   76  -29  -36  -48\n",
      "   48  -69  -10   42   42  -24   13  -10  -14  -14  -26   31   20  -35\n",
      "   35  -18   -7   11   60  -30  -22   -7  -67   18   32   68  -72   -7\n",
      "  -43   21 -128  -27   69  118   54  -12   24  -16    2   12   66  -34\n",
      " -114   88  -35   20   52  -77  -34  -30    8  -26  -42   97  -68  -78\n",
      "  -31   15   55   19  -26   -7   14  121   51    7  -73   11    4  119\n",
      "  -22   38   26   -6   20    5   44 -100  -36  -44   14  -16 -126    5\n",
      "  -14  -19  -55  111  -56   56   23   22   -2   36   84   45  -33  -20\n",
      "  -82  -53  -48  -78   16  -44    4  -26  -63  -88  -10  -22   20   12\n",
      "   30    9  -28   53   26  -64  -93  -24   -1   29  -11  -33  126  127\n",
      "  -33  -43  -44   25   38   11   23   13  -24   13   25  -65  -40  -33\n",
      "   57  -38  -67   46  -29   90   51   71   44  -26    4   90  -44   46\n",
      "   41   56  -18  -31  -75  -10  -37  -19  -95  -25   95  -31   23   73\n",
      "  -53  -39  -25 -122   54   16    4   31  -21   51  -41  -50  -13  -32\n",
      "   44  -32    5  -29   54  127  -15   -8   11   52   34  -33 -101   50\n",
      "  -49   -5  -94   48   84  -17   42   81   12  -57  -74    4   -1   22\n",
      "   51   40   29   10 -114  -66  -67   20   53   61   -3  -15  101  -76\n",
      "   52   54  -19    7  -61   12  -53   84  -38   10   44  -26  -39   40\n",
      "   38    4  -76   69  107   -4    3   12  -25   20   16   29  -73 -127\n",
      "   18  -36  -52   57   26  -20  -48    3   83  -84   19  -28  -19   13\n",
      "  -34  -15    1   31   -5  -15  -23    5  -11  -38    1   10   -7   63\n",
      "   37  -42   32   73    5  -78   37    6  -65    3   38  -74  -33   39\n",
      "   -5   78  -30   -1   -3  -16   -9  -34  -25   10   47   -5  101   98\n",
      "   13   26   73   -2  -62   -8   17    9  -26    4  -63   23  -61  -43\n",
      "    3   10   20   12   16   47   -5   -1   53  -24 -123   -5   -5  -37\n",
      "  -20   75    8   -5   35   93   39   49   33   38   14   64  -81  -64\n",
      "   32  -75   32   53    4   -6    0   41   51   40   98  -17  -81  -34\n",
      "  111   92   38   25   81 -113  -61 -114   54   22  -25  -13  127   84\n",
      "   31  -36   76   59   -8   22   -1    6  -32   47  -36   16    6  -31\n",
      "   39  -74   43   34   -2   67   -3  -48    8   19  118  -77   -4  -20\n",
      "   22   -4  -77    6  -49  -22    8   37  -69  -51  -27  -40   32   13\n",
      "   79   77  -49   28   36  -60  -54  -56  -30  -13   83   35   39   20\n",
      "  -22    3 -127   32  -46  -30   68   26   77  -41  -96  -38  -63   56\n",
      "  -15   71 -119    5   77   -7   46   58   44   50  -53   15   13  -90\n",
      "   33   18  -31   21  -27 -101    4   33   47  -21  -19   15   18   14\n",
      "  -43  -80   51   45  -35   -6   36  -79   41   55  -35   76    7    1\n",
      "   -5   25   37    0  -23  -34  -47   -7   12    8   19   -3   31  -33\n",
      "  -15   48  -25    1  -87 -127  -60   70  -38   40  -13   49  -21  -17\n",
      "  -39    1  -56  -25   20   33  -19  -38   -5   35   -9  -91  -11  -14\n",
      "  -33  -52    6   13   -7   12    9   33  -39   33   42   -7   82  -47\n",
      "   18  -27  -63   30  -10  -26  -48   -1   25   33  -64    5   27   63\n",
      "   12   21   28  -33   12  -75  -26    1  -23  -24  -24   -4   40  -46\n",
      "   70   73  -15   -8  -39   13   54  -52   44  127   10    5  -58  -22\n",
      "    8   11   16    3   -3   31  -58  -15   -7   -1   -1  -58  -33   18\n",
      "  -19   25  -10   43   22   17  -37   94  -46   22    6   43  -44   -8\n",
      "  -27   23    5   46  -36  -20   33  -57    9  -28   25   -9    6  -35\n",
      "   76  -40   18  -34  -36   19  -19  -13  -62  -21  -14  -32   51   14\n",
      "  -39   -4  -38   34  -33    4   22  -81   10    4    4  -10   65  127\n",
      "   47  -78   74   13   53  -42  -76   65  -18  -59  -27 -117  -26  -21\n",
      "   34    9  -40   64  -39  -81   64   -4  -29  -91  -13  127   71  -59\n",
      "  -50  -34  -21   32   22  -13    6   22   40   63   -6   93  116 -127\n",
      "  -53  -74   53  -52  -86  -35  -63   21  107   73   48  -68    3   68\n",
      "  -74   44  125  -35  -63  -28  -70  -25  -93  -25  -43  -27  -14   40\n",
      "   43   18   30   17   29  -89 -103  -17   62   25]\n",
      "\n",
      "Extracting weights from layer: fc\n",
      "Weight Shape: (1920,), Int8 Weights:\n",
      "[ -2  20  -2 ...  -8 -17 -53]\n",
      "\n",
      "The test accuracy after quantization is: 97.13%\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the test dataset and store the accuracy\n",
    "model.eval()\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "\n",
    "# Extract the int8 weights from all quantized layers in the model and save them to a list\n",
    "quantized_weights_list = print_quantized_weights(model)\n",
    "\n",
    "print(f\"The test accuracy after quantization is: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto4ET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
